name: Daily LME Copper Data Scraping

on:
  schedule:
    # Run daily at 7:00 AM UTC (after markets close)
    - cron: '0 7 * * *'
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [ main ]
    paths:
      - 'lme_scraper.py'
      - '.github/workflows/daily-data-scraping.yml'

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data
    
    - name: Run LME data scraper
      run: |
        python lme_scraper.py
        echo "Scraping completed at $(date)" >> scraping.log
    
    - name: Check for data changes
      id: check_changes
      run: |
        if [ -f data/lme_copper_historical_data.csv ]; then
          echo "data_exists=true" >> $GITHUB_OUTPUT
          # Check if there are actual changes in the CSV
          if git diff --quiet data/lme_copper_historical_data.csv; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi
        else
          echo "data_exists=false" >> $GITHUB_OUTPUT
          echo "has_changes=true" >> $GITHUB_OUTPUT
        fi
    
    - name: Configure Git
      if: steps.check_changes.outputs.has_changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push changes
      if: steps.check_changes.outputs.has_changes == 'true'
      run: |
        git add data/lme_copper_historical_data.csv scraping.log
        git commit -m "Update LME copper data - $(date '+%Y-%m-%d %H:%M:%S UTC')" || exit 0
        git push
    
    - name: Upload CSV as artifact
      if: steps.check_changes.outputs.data_exists == 'true'
      uses: actions/upload-artifact@v3
      with:
        name: lme-copper-data-${{ github.run_number }}
        path: data/lme_copper_historical_data.csv
        retention-days: 30
    
    - name: Create data summary
      if: steps.check_changes.outputs.data_exists == 'true'
      run: |
        echo "## LME Copper Data Summary" > data_summary.md
        echo "**Last Updated:** $(date)" >> data_summary.md
        echo "**File:** data/lme_copper_historical_data.csv" >> data_summary.md
        if [ -f data/lme_copper_historical_data.csv ]; then
          echo "**Total Records:** $(tail -n +2 data/lme_copper_historical_data.csv | wc -l)" >> data_summary.md
          echo "**Date Range:** $(tail -n +2 data/lme_copper_historical_data.csv | head -1 | cut -d',' -f1) to $(tail -n +2 data/lme_copper_historical_data.csv | tail -1 | cut -d',' -f1)" >> data_summary.md
        fi
    
    - name: Update README with latest stats
      if: steps.check_changes.outputs.data_exists == 'true'
      run: |
        if [ -f README.md ] && [ -f data/lme_copper_historical_data.csv ]; then
          # Update last updated timestamp in README
          sed -i "s/Last Updated: .*/Last Updated: $(date)/" README.md || true
          
          # Calculate basic stats
          TOTAL_RECORDS=$(tail -n +2 data/lme_copper_historical_data.csv | wc -l)
          FIRST_DATE=$(tail -n +2 data/lme_copper_historical_data.csv | head -1 | cut -d',' -f1)
          LAST_DATE=$(tail -n +2 data/lme_copper_historical_data.csv | tail -1 | cut -d',' -f1)
          
          # Update stats in README if sections exist
          sed -i "s/Total Records: .*/Total Records: $TOTAL_RECORDS/" README.md || true
          sed -i "s/Date Range: .*/Date Range: $FIRST_DATE to $LAST_DATE/" README.md || true
        fi
